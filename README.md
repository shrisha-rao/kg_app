# eDiscovery Knowledge Graph Engine 
![Python](https://img.shields.io/badge/python-3.9%2B-blue)
![Google Cloud](https://img.shields.io/badge/Google-Cloud-orange)
![Status](https://img.shields.io/badge/status-alpha-yellow)

## Overview
A deep-tech SaaS platform that uses automated knowledge graphs to revolutionize the electronic discovery (eDiscovery) process for legal and compliance investigations.

Turn your corpus of text(pdf, emails, chats, etc,,) into a queryable knowledge base. This tool processes  documents, uses Large Language Models (LLMs) to extract structured knowledge (entities & relationships), builds a dynamic Knowledge Graph, and enables semantic querying over your entire corpus.

 ## âœ¨ Features

    ðŸ“„ Document Processing: Upload and manage documents (PDF, emails, etc.).

    ðŸ§  AI-Powered Extraction: Leverage LLMs to identify key entities (e.g., people, dates, organizations, monetary figures) and their relationships.

    ðŸ•¸ï¸ Knowledge Graph Construction: Automatically infers and visualizes a semantic relationships.

    â“ Intelligent Q&A and Discovery: Ask complex, natural language questions and retrive the "smoking gun".

    â˜ï¸ Cloud-Native & Scalable: Designed for the cloud (GCP) with a FastAPI backend for high performance.

## Doker RUN 

```bash
git clone https://github.com/shrisha-rao/kg_app
cd kg_app

# Uses Emulators so we can avoid setting up GCP 

docker compose build web
docker compose up web

```
### TEST APP wih API access 
go to : http://0.0.0.0:8000/docs#/


## Architecture
```mermaid
flowchart TD
    User[User] --> API[FastAPI Backend]
    
    subgraph Backend [Application Layer]
        API --> Service[Processing Services]
        Service --> LLM[LLM Integration]
    end
    
    subgraph GCP [Google Cloud Platform]
        Storage[Cloud Storage]
        AI[Vertex AI LLMs]
        VectorDB[Vertex AI<br>Matching Engine]
        GraphDB[ArangoDB Graph]
    end
    
    Service --> Storage
    LLM --> AI
    Service --> VectorDB
    Service --> GraphDB
    
    VectorDB --> Graph[Knowledge Graph]
    GraphDB --> Graph
    
    Graph --> Q&A[Query & Insights]
    Q&A --> User
```


## Current Implementation Status

### âœ… Completed Components

#### Core Infrastructure
- **FastAPI Application** with modular architecture
- **Configuration Management** with environment variables
- **Dockerization** with multi-stage builds
- **Terraform Infrastructure** for GCP resources
- **Multi-environment setup** (dev, stage, prod)

#### Authentication & User Management
- **Firebase Authentication** integration
- **User model** with Firestore storage
- **Protected API endpoints** with JWT tokens
- **Role-based access control**

#### File Processing Pipeline
- **PDF text extraction** with PyMuPDF
- **Modular embedding generation** system
- **Abstract base classes** for easy implementation swapping
- **Local embedding generator** using Sentence Transformers
- **Vertex AI embedding generator** for cloud-based embeddings

#### Services Architecture
- **Abstract service interfaces** for storage, vector DB, graph DB, and LLM
- **GCP Cloud Storage** implementation for file storage
- **Modular design** for easy component replacement

### ðŸš§ Partially Implemented

#### Vector Database Integration
- **Vertex AI Matching Engine service** partially implemented
- **Base interface** defined for vector operations
- **Metadata storage solution** designed but not fully implemented

#### Knowledge Graph Storage
- **ArangoDB interface** defined but not implemented
- **Graph operations** schema designed

#### Query Processing
- **LLM interface** defined but not implemented
- **Query orchestration** logic outlined

### ðŸ“‹ Pending Implementation

#### Complete Vector DB Service
- **Metadata integration** with Firestore
- **Batch operations** with rate limiting
- **Error handling** and retry logic
- **Monitoring** and performance tracking

#### Graph Database Implementation
- **ArangoDB integration** for knowledge graph
- **Entity-relationship storage**
- **Graph traversal** operations

#### LLM Integration
- **Vertex AI LLM** implementation
- **Prompt engineering** for research questions
- **Response formatting** and citation

#### Advanced Features
- **Compliance filtering** for public/private data
- **Advanced caching** strategies
- **Data backup** and migration tools
- **Admin dashboard** for management

## Project Structure

```
research-kg-app/
â”œâ”€â”€ docker/                          # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile                   # Production Dockerfile
â”‚   â”œâ”€â”€ Dockerfile.dev               # Development Dockerfile
â”‚   â””â”€â”€ docker-compose.yml           # Local development setup
â”œâ”€â”€ infrastructure/                  # Terraform configurations
â”‚   â”œâ”€â”€ modules/                     # Reusable Terraform modules
â”‚   â”‚   â”œâ”€â”€ gke/                     # GKE cluster module
â”‚   â”‚   â”œâ”€â”€ cloud-run/               # Cloud Run service module
â”‚   â”‚   â”œâ”€â”€ vertex-ai/               # Vertex AI resources module
â”‚   â”‚   â””â”€â”€ networking/              # Networking resources module
â”‚   â”œâ”€â”€ dev/                         # Development environment
â”‚   â”‚   â”œâ”€â”€ main.tf                  # Main configuration
â”‚   â”‚   â”œâ”€â”€ variables.tf             # Environment variables
â”‚   â”‚   â”œâ”€â”€ outputs.tf               # Output values
â”‚   â”‚   â””â”€â”€ terraform.tfvars         # Variable values
â”‚   â”œâ”€â”€ stage/                       # Staging environment
â”‚   â”‚   â””â”€â”€ ... (same as dev)
â”‚   â””â”€â”€ prod/                        # Production environment
â”‚       â””â”€â”€ ... (same as dev)
â”œâ”€â”€ src/                             # Application source code
â”‚   â”œâ”€â”€ main.py                      # FastAPI application entry point
â”‚   â”œâ”€â”€ config.py                    # Configuration management
â”‚   â”œâ”€â”€ models/                      # Pydantic models
â”‚   â”‚   â”œâ”€â”€ user.py                  # User models âœ…
â”‚   â”‚   â”œâ”€â”€ paper.py                 # Paper models âœ…
â”‚   â”‚   â””â”€â”€ query.py                 # Query models âœ…
â”‚   â”œâ”€â”€ services/                    # Core services
â”‚   â”‚   â”œâ”€â”€ storage/                 # Storage abstractions
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py              # Abstract base class âœ…
â”‚   â”‚   â”‚   â””â”€â”€ gcp_cloud_storage.py # GCP implementation âœ…
â”‚   â”‚   â”œâ”€â”€ vector_db/               # Vector database abstractions
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py              # Abstract base class âœ…
â”‚   â”‚   â”‚   â””â”€â”€ vertex_ai_matching_engine.py # Partial implementation ðŸš§
â”‚   â”‚   â”‚   â””â”€â”€ vertex_ai_matching_engine_with_metadata.py #Enhanced Matching Engine service that handles metadata storage.
â”‚   â”‚   â”œâ”€â”€ graph_db/                # Graph database abstractions
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py              # Abstract base class âœ…
â”‚   â”‚   â”‚   â””â”€â”€ arangodb.py          # Not implemented ðŸ“‹
â”‚   â”‚   â”œâ”€â”€ llm/                     # LLM service abstractions
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py              # Abstract base class âœ…
â”‚   â”‚   â”‚   â””â”€â”€ vertex_ai.py         # Not implemented ðŸ“‹
â”‚   â”‚   â”œâ”€â”€ file_processing.py       # File processing orchestration âœ…
â”‚   â”‚   â”œâ”€â”€ query_processing.py      # Query processing orchestration ðŸš§
â”‚   â”‚   â””â”€â”€ compliance.py            # Compliance filtering ðŸ“‹
â”‚   â”œâ”€â”€ processing/                  # Processing modules
â”‚   â”‚   â”œâ”€â”€ embedding/               # Embedding generation module
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py          # Package initialization âœ…
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py              # Abstract base class âœ…
â”‚   â”‚   â”‚   â”œâ”€â”€ local.py             # Local implementation âœ…
â”‚   â”‚   â”‚   â”œâ”€â”€ vertex_ai.py         # Vertex AI implementation âœ…
â”‚   â”‚   â”‚   â””â”€â”€ utils.py             # Common utilities âœ…
â”‚   â”‚   â”œâ”€â”€ pdf_extractor.py         # PDF text extraction âœ…
â”‚   â”‚   â”œâ”€â”€ ner_extractor.py         # NER and relation extraction ðŸ“‹
â”‚   â”‚   â””â”€â”€ embedding_generator.py   # Legacy file (replaced) âœ…
â”‚   â”œâ”€â”€ api/                         # API endpoints
â”‚   â”‚   â”œâ”€â”€ upload.py                # File upload endpoints âœ…
â”‚   â”‚   â”œâ”€â”€ query.py                 # Query endpoints ðŸš§
â”‚   â”‚   â”œâ”€â”€ papers.py                # Paper management endpoints âœ…
â”‚   â”‚   â””â”€â”€ auth.py                  # Authentication endpoints âœ…
â”‚   â”œâ”€â”€ utils/                       # Utility functions
â”‚   â”‚   â”œâ”€â”€ cache.py                 # Redis cache wrapper âœ…
â”‚   â”‚   â”œâ”€â”€ auth.py                  # Authentication utilities âœ…
â”‚   â”‚   â””â”€â”€ logging.py               # Logging configuration âœ…
â”‚   â””â”€â”€ scripts/                     # Maintenance scripts
â”‚       â”œâ”€â”€ init_graph_db.py         # Initialize graph database ðŸ“‹
â”‚       â”œâ”€â”€ backup_vectors.py        # Backup vector data ðŸ“‹
â”‚       â””â”€â”€ migrate_data.py          # Data migration utilities ðŸ“‹
â”œâ”€â”€ tests/                           # Test suite
â”‚   â”œâ”€â”€ unit/                        # Unit tests
â”‚   â”‚   â”œâ”€â”€ test_services.py         # Service tests ðŸ“‹
â”‚   â”‚   â”œâ”€â”€ test_processing.py       # Processing tests ðŸ“‹
â”‚   â”‚   â””â”€â”€ test_api.py              # API tests ðŸ“‹
â”‚   â”œâ”€â”€ integration/                 # Integration tests
â”‚   â”‚   â”œâ”€â”€ test_storage_integration.py ðŸ“‹
â”‚   â”‚   â”œâ”€â”€ test_vector_db_integration.py ðŸ“‹
â”‚   â”‚   â””â”€â”€ test_graph_db_integration.py ðŸ“‹
â”‚   â”œâ”€â”€ conftest.py                  # Test fixtures ðŸ“‹
â”‚   â””â”€â”€ pytest.ini                   # Pytest configuration ðŸ“‹
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ architecture.md              # Architecture decisions âœ…
â”‚   â”œâ”€â”€ api.md                       # API documentation ðŸš§
â”‚   â”œâ”€â”€ deployment.md                # Deployment guide ðŸš§
â”‚   â””â”€â”€ development.md               # Development setup ðŸš§
â”œâ”€â”€ scripts/                         # Deployment and utility scripts
â”‚   â”œâ”€â”€ deploy.sh                    # Deployment script ðŸ“‹
â”‚   â”œâ”€â”€ build.sh                     # Docker build script ðŸ“‹
â”‚   â”œâ”€â”€ test.sh                      # Test runner ðŸ“‹
â”‚   â””â”€â”€ terraform-apply.sh           # Terraform execution wrapper ðŸ“‹
â”œâ”€â”€ .github/                         # GitHub workflows
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml                   # Continuous integration ðŸ“‹
â”‚       â”œâ”€â”€ cd-dev.yml               # Development deployment ðŸ“‹
â”‚       â”œâ”€â”€ cd-stage.yml             # Staging deployment ðŸ“‹
â”‚       â””â”€â”€ cd-prod.yml              # Production deployment ðŸ“‹
â”œâ”€â”€ .dockerignore                    # Docker ignore file âœ…
â”œâ”€â”€ .gitignore                       # Git ignore file âœ…
â”œâ”€â”€ .env.example                     # Environment variables template âœ…
â”œâ”€â”€ requirements.txt                 # Production dependencies âœ…
â”œâ”€â”€ requirements-dev.txt             # Development dependencies âœ…
â”œâ”€â”€ Dockerfile                       # Main Dockerfile âœ…
â”œâ”€â”€ docker-compose.yml               # Main compose file âœ…
â”œâ”€â”€ terraform.tfvars.example         # Terraform variables template âœ…
â””â”€â”€ README.md                        # Project overview âœ…
```

## Getting Started

### Prerequisites
- Python 3.9+
- Docker
- Terraform
- Google Cloud SDK
- GCP account with billing enabled

### Local Development
1. Clone the repository
2. Set up environment variables: `cp .env.example .env`
3. Install dependencies: `pip install -r requirements.txt -r requirements-dev.txt`
4. Run the application: `uvicorn src.main:app --reload`

### Deployment
1. Initialize Terraform: `cd infrastructure/dev && terraform init`
2. Plan deployment: `terraform plan`
3. Apply configuration: `terraform apply`
4. Build and deploy Docker image

## Configuration

### Environment Variables
- `GCP_PROJECT_ID`: Your GCP project ID
- `GCP_REGION`: GCP region for deployment
- `EMBEDDING_TYPE`: "local" or "vertex_ai"
- `LOCAL_EMBEDDING_MODEL`: Sentence Transformers model name
- `VERTEX_AI_EMBEDDING_MODEL`: Vertex AI model name
- `VERTEX_AI_INDEX_ID`: Matching Engine index ID
- `VERTEX_AI_INDEX_ENDPOINT_ID`: Matching Engine endpoint ID

## API Endpoints

### Authentication
- `POST /auth/signup`: Create a new user account
- `POST /auth/login`: Login with Firebase token
- `GET /auth/me`: Get current user information
- `PUT /auth/me`: Update user information
- `POST /auth/refresh`: Refresh authentication token
- `POST /auth/logout`: Logout endpoint

### Papers Management
- `POST /papers/upload`: Upload a pdf
- `GET /papers/`: Get user's papers
- `GET /papers/{paper_id}`: Get paper details
- `PUT /papers/{paper_id}`: Update paper metadata
- `DELETE /papers/{paper_id}`: Delete a paper

### Query Interface
- `POST /query`: Query the knowledge graph

## Next Steps

1. Complete Vertex AI Matching Engine implementation
2. Implement ArangoDB integration for knowledge graph
3. Add Vertex AI LLM integration for question answering
4. Implement compliance filtering for public/private data
5. Add comprehensive test suite
6. Set up CI/CD pipelines
7. Implement monitoring and alerting

## Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a pull request

## License


## Support

For support, please open an issue in the GitHub repository or contact the development team.
