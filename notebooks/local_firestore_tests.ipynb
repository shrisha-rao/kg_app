{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5579bfa1-3cb8-4ff8-978a-fd9ea7aeb09d",
   "metadata": {},
   "source": [
    "**This comprehensive test notebook will:**\n",
    "- Test all CRUD operations - upsert, search, delete\n",
    "\n",
    "- Verify namespace functionality - separate data spaces\n",
    "\n",
    "- Check performance - batch operations and search speed\n",
    "\n",
    "- Handle edge cases - empty inputs, similar vectors, non-existent data\n",
    "\n",
    "- Provide detailed reporting - success/failure status for each test\n",
    "\n",
    "- Include cleanup - remove test data after tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e9c374b-7c9e-4c03-8bcc-ffcdc578ec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.config:Loading ARANGODB_HOST: http://arangodb:8529\n",
      "INFO:src.config:Loading USE_MOCK_SERVICES: true\n",
      "INFO:src.services.vector_db.local_vector_db:Successfully connected to Firestore Emulator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Firestore Local Vector DB Test Suite\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# test_firestore_vector_db.ipynb\n",
    "import asyncio\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Add the project root to Python path\n",
    "sys.path.append('/app')\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Import the local vector DB service\n",
    "from src.services.vector_db.local_vector_db import LocalVectorDBService\n",
    "from src.config import settings\n",
    "\n",
    "# Initialize the service\n",
    "vector_db = LocalVectorDBService()\n",
    "\n",
    "print(\"ðŸ”¥ Firestore Local Vector DB Test Suite\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd80c8-5784-453d-be90-9ae2807dfb76",
   "metadata": {},
   "source": [
    "# Test 1: Basic Connection Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62e2705-c088-4d46-bc3f-89085ce2614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Test 1: Testing Firestore Connection...\n",
      "âœ… Connection successful! Current stats: {'vectors_count': 23, 'namespaces': ['test_namespace', 'user310', 'user101', 'user007', 'user2', 'user009', 'user_123', 'public', 'user311'], 'shards_count': 1, 'collection_name': 'vectors'}\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Basic Connection and Collection Setup\n",
    "async def test_connection():\n",
    "    print(\"ðŸ§ª Test 1: Testing Firestore Connection...\")\n",
    "    try:\n",
    "        stats = await vector_db.get_index_stats()\n",
    "        print(f\"âœ… Connection successful! Current stats: {stats}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run test\n",
    "connection_ok = await test_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caadc16f-703d-434e-9603-867336dffaa4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test 2: Generate Sample Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32223e3-bc0a-436f-87f4-0cd400956d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Generating 5 sample embeddings...\n",
      "  âœ… Generated 5 embeddings, 5 IDs, 5 metadata entries\n",
      "Sample vector: [-0.031366072595119476, 0.014946346171200275, 0.004160337150096893, 0.06344591826200485, -0.01146529708057642]...\n",
      "Sample metadata: {'title': 'Machine Learning Research Paper #0', 'authors': ['Author_0', 'Researcher_0'], 'year': 2020, 'abstract': 'This is a test abstract for Machine Learning Research Paper - document 0', 'doc_id': 'doc_0', 'is_public': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Generate Sample Embeddings\n",
    "# CORRECTED: Generate Sample Embeddings Function\n",
    "def generate_sample_embeddings(num_vectors: int = 5, dimension: int = 384) -> tuple:\n",
    "    \"\"\"Generate sample embeddings for testing - FIXED VERSION\"\"\"\n",
    "    print(f\"  Generating {num_vectors} sample embeddings...\")\n",
    "    \n",
    "    # Generate random vectors (normalized for cosine similarity)\n",
    "    vectors = []\n",
    "    for i in range(num_vectors):\n",
    "        vec = np.random.randn(dimension).astype(np.float32)\n",
    "        vec = vec / np.linalg.norm(vec)  # Normalize\n",
    "        vectors.append(vec.tolist())\n",
    "    \n",
    "    # Generate IDs and metadata - FIXED: Ensure same length\n",
    "    ids = [f\"test_doc_{i}\" for i in range(num_vectors)]\n",
    "    \n",
    "    metadatas = []\n",
    "    sample_titles = [\n",
    "        \"Machine Learning Research Paper\",\n",
    "        \"Deep Learning Applications\", \n",
    "        \"Natural Language Processing\",\n",
    "        \"Computer Vision Advances\",\n",
    "        \"Reinforcement Learning\"\n",
    "    ]\n",
    "    \n",
    "    # FIXED: Generate metadata for ALL vectors, not just first 5\n",
    "    for i in range(num_vectors):\n",
    "        title = sample_titles[i % len(sample_titles)]  # Cycle through titles if num_vectors > 5\n",
    "        metadatas.append({\n",
    "            \"title\": f\"{title} #{i}\",\n",
    "            \"authors\": [f\"Author_{i}\", f\"Researcher_{i % 5}\"],\n",
    "            \"year\": 2020 + (i % 5),\n",
    "            \"abstract\": f\"This is a test abstract for {title} - document {i}\",\n",
    "            \"doc_id\": f\"doc_{i}\",\n",
    "            \"is_public\": i % 2 == 0  # Alternate public/private\n",
    "        })\n",
    "    \n",
    "    print(f\"  âœ… Generated {len(vectors)} embeddings, {len(ids)} IDs, {len(metadatas)} metadata entries\")\n",
    "    return vectors, ids, metadatas\n",
    "\n",
    "\n",
    "def generate_sample_embeddings_OLD(num_vectors: int = 5, dimension: int = 384) -> tuple:\n",
    "    \"\"\"Generate sample embeddings for testing\"\"\"\n",
    "    print(f\"\\nðŸ§ª Test 2: Generating {num_vectors} sample embeddings...\")\n",
    "    \n",
    "    # Generate random vectors (normalized for cosine similarity)\n",
    "    vectors = []\n",
    "    for i in range(num_vectors):\n",
    "        vec = np.random.randn(dimension).astype(np.float32)\n",
    "        vec = vec / np.linalg.norm(vec)  # Normalize\n",
    "        vectors.append(vec.tolist())\n",
    "    \n",
    "    # Generate IDs and metadata\n",
    "    ids = [f\"test_doc_{i}\" for i in range(num_vectors)]\n",
    "    \n",
    "    metadatas = []\n",
    "    sample_titles = [\n",
    "        \"Machine Learning Research Paper\",\n",
    "        \"Deep Learning Applications\", \n",
    "        \"Natural Language Processing\",\n",
    "        \"Computer Vision Advances\",\n",
    "        \"Reinforcement Learning\"\n",
    "    ]\n",
    "    \n",
    "    for i, title in enumerate(sample_titles):\n",
    "        metadatas.append({\n",
    "            \"title\": title,\n",
    "            \"authors\": [f\"Author_{i}\", f\"Researcher_{i}\"],\n",
    "            \"year\": 2020 + i,\n",
    "            \"abstract\": f\"This is a test abstract for {title}\",\n",
    "            \"doc_id\": f\"doc_{i}\",\n",
    "            \"is_public\": i % 2 == 0  # Alternate public/private\n",
    "        })\n",
    "    \n",
    "    print(f\"âœ… Generated {len(vectors)} embeddings with dimension {len(vectors[0])}\")\n",
    "    return vectors, ids, metadatas\n",
    "\n",
    "# Generate sample data\n",
    "vectors, ids, metadatas = generate_sample_embeddings()\n",
    "print(f\"Sample vector: {vectors[0][:5]}...\")  # Show first 5 dimensions\n",
    "print(f\"Sample metadata: {metadatas[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6a5f12d-555f-456b-9ebc-9a3b82e596d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Debug: Checking vector generation...\n",
      "âŒ BROKEN: vectors: 20, ids: 20, metadatas: 5\n",
      "âœ… FIXED: vectors: 20, ids: 20, metadatas: 20\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check lengths before running performance test\n",
    "def debug_length_check():\n",
    "    print(\"ðŸ” Debug: Checking vector generation...\")\n",
    "    \n",
    "    # Test the original broken function\n",
    "    def original_broken_function(num_vectors=20):\n",
    "        vectors = [f\"vector_{i}\" for i in range(num_vectors)]\n",
    "        ids = [f\"id_{i}\" for i in range(num_vectors)]\n",
    "        \n",
    "        metadatas = []\n",
    "        sample_titles = [\"Title1\", \"Title2\", \"Title3\", \"Title4\", \"Title5\"]\n",
    "        for i, title in enumerate(sample_titles):\n",
    "            metadatas.append({\"title\": title})\n",
    "            \n",
    "        return vectors, ids, metadatas\n",
    "    \n",
    "    vectors, ids, metadatas = original_broken_function(20)\n",
    "    print(f\"âŒ BROKEN: vectors: {len(vectors)}, ids: {len(ids)}, metadatas: {len(metadatas)}\")\n",
    "    \n",
    "    # Test the fixed function\n",
    "    def fixed_function(num_vectors=20):\n",
    "        vectors = [f\"vector_{i}\" for i in range(num_vectors)]\n",
    "        ids = [f\"id_{i}\" for i in range(num_vectors)]\n",
    "        \n",
    "        metadatas = []\n",
    "        sample_titles = [\"Title1\", \"Title2\", \"Title3\", \"Title4\", \"Title5\"]\n",
    "        for i in range(num_vectors):\n",
    "            title = sample_titles[i % len(sample_titles)]\n",
    "            metadatas.append({\"title\": f\"{title}_{i}\"})\n",
    "            \n",
    "        return vectors, ids, metadatas\n",
    "    \n",
    "    vectors, ids, metadatas = fixed_function(20)\n",
    "    print(f\"âœ… FIXED: vectors: {len(vectors)}, ids: {len(ids)}, metadatas: {len(metadatas)}\")\n",
    "\n",
    "debug_length_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d08c5-137e-45ae-babd-3eaa8766491f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test 3: Upsert/Insert Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a9c9fc-0cee-4205-a562-9a502acede74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Test 3: Testing Upsert Operations...\n",
      "\n",
      "ðŸ“¦ Upserting to namespace: user_123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.services.vector_db.local_vector_db:Upserted batch of 5 vectors to Firestore\n",
      "INFO:src.services.vector_db.local_vector_db:Upserted batch of 5 vectors to Firestore\n",
      "INFO:src.services.vector_db.local_vector_db:Upserted batch of 5 vectors to Firestore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Successfully upserted: 5 vectors\n",
      "  âœ… No errors\n",
      "\n",
      "ðŸ“¦ Upserting to namespace: public\n",
      "  âœ… Successfully upserted: 5 vectors\n",
      "  âœ… No errors\n",
      "\n",
      "ðŸ“¦ Upserting to namespace: test_namespace\n",
      "  âœ… Successfully upserted: 5 vectors\n",
      "  âœ… No errors\n",
      "\n",
      "ðŸ“Š Final collection stats: {'vectors_count': 15, 'namespaces': ['test_namespace', 'user_123', 'public'], 'shards_count': 1, 'collection_name': 'vectors'}\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Upsert/Insert Test\n",
    "async def test_upsert():\n",
    "    print(f\"\\nðŸ§ª Test 3: Testing Upsert Operations...\")\n",
    "    \n",
    "    # Test with different namespaces\n",
    "    namespaces = [\"user_123\", \"public\", \"test_namespace\"]\n",
    "    \n",
    "    for namespace in namespaces:\n",
    "        print(f\"\\nðŸ“¦ Upserting to namespace: {namespace}\")\n",
    "        \n",
    "        try:\n",
    "            results = await vector_db.upsert_embeddings(\n",
    "                vectors=vectors,\n",
    "                ids=[f\"{namespace}_{id}\" for id in ids],  # Make IDs namespace-specific\n",
    "                metadatas=metadatas,\n",
    "                namespace=namespace\n",
    "            ) \n",
    "            \n",
    "            # Check results\n",
    "            successes = [r for r in results if r[\"status\"] == \"success\"]\n",
    "            errors = [r for r in results if r[\"status\"] == \"error\"]\n",
    "            \n",
    "            print(f\"  âœ… Successfully upserted: {len(successes)} vectors\")\n",
    "            if errors:\n",
    "                print(f\"  âŒ Errors: {len(errors)}\")\n",
    "                for error in errors:\n",
    "                    print(f\"    - {error}\")\n",
    "            else:\n",
    "                print(f\"  âœ… No errors\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Upsert failed for namespace {namespace}: {e}\")\n",
    "    \n",
    "    # Check final stats\n",
    "    stats = await vector_db.get_index_stats()\n",
    "    print(f\"\\nðŸ“Š Final collection stats: {stats}\")\n",
    "\n",
    "# Run test\n",
    "await test_upsert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc5e96-6716-4f0c-a3d1-6f2e54ef1605",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test 4: Search Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "142849ff-0f15-4243-9498-0e9f9df456e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Test 4: Testing Search Operations...\n",
      "\n",
      "ðŸ” Test 4.1: Search across all namespaces\n",
      "  Found 3 results:\n",
      "    1. ID: public_test_doc_0, Distance: 0.0000\n",
      "       Title: Machine Learning Research Paper\n",
      "    2. ID: test_namespace_test_doc_0, Distance: 0.0000\n",
      "       Title: Machine Learning Research Paper\n",
      "    3. ID: user_123_test_doc_0, Distance: 0.0000\n",
      "       Title: Machine Learning Research Paper\n",
      "\n",
      "ðŸ” Test 4.2: Search within 'user_123' namespace\n",
      "  Found 2 results in namespace 'user_123':\n",
      "    1. ID: user_123_test_doc_0, Distance: 0.0000\n",
      "    2. ID: user_123_test_doc_4, Distance: 0.9278\n",
      "\n",
      "ðŸ” Test 4.3: Search with metadata filters\n",
      "  Found 0 public documents:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/google/cloud/firestore_v1/base_collection.py:304: UserWarning: Detected filter using positional arguments. Prefer using the 'filter' keyword argument instead.\n",
      "  return query.where(field_path, op_string, value)\n"
     ]
    }
   ],
   "source": [
    "async def test_search():\n",
    "    print(f\"\\nðŸ§ª Test 4: Testing Search Operations...\")\n",
    "    \n",
    "    # Use the first vector as query\n",
    "    query_vector = vectors[0]\n",
    "    \n",
    "    # Test 4.1: Search across all namespaces\n",
    "    print(f\"\\nðŸ” Test 4.1: Search across all namespaces\")\n",
    "    try:\n",
    "        results = await vector_db.search(\n",
    "            query_embedding=query_vector,\n",
    "            top_k=3,\n",
    "            namespace=None  # Search all namespaces\n",
    "        )\n",
    "        \n",
    "        print(f\"  Found {len(results)} results:\")\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"    {i+1}. ID: {result['id']}, Distance: {result['distance']:.4f}\")\n",
    "            print(f\"       Title: {result['metadata'].get('title', 'N/A')}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Search failed: {e}\")\n",
    "    \n",
    "    # Test 4.2: Search within specific namespace\n",
    "    print(f\"\\nðŸ” Test 4.2: Search within 'user_123' namespace\")\n",
    "    try:\n",
    "        results = await vector_db.search(\n",
    "            query_embedding=query_vector,\n",
    "            top_k=2,\n",
    "            namespace=\"user_123\"\n",
    "        )\n",
    "        \n",
    "        print(f\"  Found {len(results)} results in namespace 'user_123':\")\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"    {i+1}. ID: {result['id']}, Distance: {result['distance']:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Namespace search failed: {e}\")\n",
    "    \n",
    "    # Test 4.3: Search with filters\n",
    "    print(f\"\\nðŸ” Test 4.3: Search with metadata filters\")\n",
    "    try:\n",
    "        results = await vector_db.search(\n",
    "            query_embedding=query_vector,\n",
    "            top_k=5,\n",
    "            namespace=None,\n",
    "            filter={\"is_public\": [True]}  # Only public documents\n",
    "        )\n",
    "        \n",
    "        print(f\"  Found {len(results)} public documents:\")\n",
    "        for i, result in enumerate(results):\n",
    "            is_public = result['metadata'].get('is_public', False)\n",
    "            print(f\"    {i+1}. ID: {result['id']}, Public: {is_public}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Filtered search failed: {e}\")\n",
    "\n",
    "# Run test\n",
    "await test_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77537b53-e191-425b-ad8d-5a0cf015719c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test 5: Delete Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66bed259-03f5-4822-be9d-0600d3104915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Test 5: Testing Delete Operations...\n",
      "ðŸ—‘ï¸  Deleting 2 documents: ['user_123_test_doc_0', 'user_123_test_doc_1']\n",
      "  âœ… Successfully deleted: 2 documents\n",
      "\n",
      "ðŸ” Verifying deletion by searching...\n",
      "  Remaining documents in 'user_123': 3\n",
      "  Remaining IDs: ['user_123_test_doc_4', 'user_123_test_doc_3', 'user_123_test_doc_2']\n",
      "  âœ… Document user_123_test_doc_0 successfully deleted\n",
      "  âœ… Document user_123_test_doc_1 successfully deleted\n"
     ]
    }
   ],
   "source": [
    "async def test_delete():\n",
    "    print(f\"\\nðŸ§ª Test 5: Testing Delete Operations...\")\n",
    "    \n",
    "    # Delete documents from user_123 namespace\n",
    "    docs_to_delete = [f\"user_123_{id}\" for id in ids[:2]]  # Delete first 2 docs\n",
    "    \n",
    "    print(f\"ðŸ—‘ï¸  Deleting {len(docs_to_delete)} documents: {docs_to_delete}\")\n",
    "    \n",
    "    try:\n",
    "        delete_results = await vector_db.delete(docs_to_delete)\n",
    "        \n",
    "        successes = [r for r in delete_results if r[\"status\"] == \"success\"]\n",
    "        errors = [r for r in delete_results if r[\"status\"] == \"error\"]\n",
    "        \n",
    "        print(f\"  âœ… Successfully deleted: {len(successes)} documents\")\n",
    "        if errors:\n",
    "            print(f\"  âŒ Delete errors: {len(errors)}\")\n",
    "            for error in errors:\n",
    "                print(f\"    - {error}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Delete operation failed: {e}\")\n",
    "    \n",
    "    # Verify deletion by searching\n",
    "    print(f\"\\nðŸ” Verifying deletion by searching...\")\n",
    "    try:\n",
    "        query_vector = vectors[0]\n",
    "        results = await vector_db.search(\n",
    "            query_embedding=query_vector,\n",
    "            top_k=10,\n",
    "            namespace=\"user_123\"\n",
    "        )\n",
    "        \n",
    "        remaining_ids = [r[\"id\"] for r in results]\n",
    "        print(f\"  Remaining documents in 'user_123': {len(remaining_ids)}\")\n",
    "        print(f\"  Remaining IDs: {remaining_ids}\")\n",
    "        \n",
    "        # Check if deleted docs are gone\n",
    "        for deleted_id in docs_to_delete:\n",
    "            if deleted_id in remaining_ids:\n",
    "                print(f\"  âš ï¸  Document {deleted_id} still exists!\")\n",
    "            else:\n",
    "                print(f\"  âœ… Document {deleted_id} successfully deleted\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Verification search failed: {e}\")\n",
    "\n",
    "# Run test\n",
    "await test_delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dea0b4-acd9-43b1-b1b2-7c624f6a807a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test 6: Performance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed0385b5-019b-482f-8a93-8985c30cc467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Test 6: Testing Performance...\n",
      "\n",
      "ðŸ§ª Test 2: Generating 20 sample embeddings...\n",
      "âœ… Generated 20 embeddings with dimension 384\n",
      "â±ï¸  Testing with 20 vectors...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Vectors, IDs, and metadatas must have the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ðŸ§¹ Cleaned up performance test data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Run test\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m test_performance()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtest_performance\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Test upsert performance\u001b[39;00m\n\u001b[32m     15\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m results = \u001b[38;5;28;01mawait\u001b[39;00m vector_db.upsert_embeddings(\n\u001b[32m     17\u001b[39m     vectors=large_vectors,\n\u001b[32m     18\u001b[39m     ids=[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mperf_test_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m large_ids],\n\u001b[32m     19\u001b[39m     metadatas=large_metadatas,\n\u001b[32m     20\u001b[39m     namespace=\u001b[33m\"\u001b[39m\u001b[33mperformance_test\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     21\u001b[39m )\n\u001b[32m     22\u001b[39m upsert_time = time.time() - start_time\n\u001b[32m     24\u001b[39m successes = \u001b[38;5;28mlen\u001b[39m([r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mif\u001b[39;00m r[\u001b[33m\"\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33msuccess\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/src/services/vector_db/local_vector_db.py:47\u001b[39m, in \u001b[36mLocalVectorDBService.upsert_embeddings\u001b[39m\u001b[34m(self, vectors, ids, metadatas, namespace)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Upsert embeddings into Firestore with vector support.\"\"\"\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vectors) != \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vectors) != \u001b[38;5;28mlen\u001b[39m(metadatas):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     48\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mVectors, IDs, and metadatas must have the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m batch_size = settings.matching_engine_batch_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m100\u001b[39m\n\u001b[32m     51\u001b[39m results = []\n",
      "\u001b[31mValueError\u001b[39m: Vectors, IDs, and metadatas must have the same length"
     ]
    }
   ],
   "source": [
    "# Test 6: Performance Test - FIXED VERSION\n",
    "async def test_performance():\n",
    "    print(f\"\\nðŸ§ª Test 6: Testing Performance...\")\n",
    "    \n",
    "    # FIXED: Generate consistent number of vectors, ids, and metadatas\n",
    "    def generate_large_sample_embeddings(num_vectors: int = 20, dimension: int = 384) -> tuple:\n",
    "        \"\"\"Generate sample embeddings for performance testing\"\"\"\n",
    "        print(f\"  Generating {num_vectors} sample embeddings...\")\n",
    "        \n",
    "        # Generate random vectors (normalized for cosine similarity)\n",
    "        vectors = []\n",
    "        for i in range(num_vectors):\n",
    "            vec = np.random.randn(dimension).astype(np.float32)\n",
    "            vec = vec / np.linalg.norm(vec)  # Normalize\n",
    "            vectors.append(vec.tolist())\n",
    "        \n",
    "        # Generate IDs and metadata - FIXED: Ensure same length\n",
    "        ids = [f\"test_doc_{i}\" for i in range(num_vectors)]\n",
    "        \n",
    "        metadatas = []\n",
    "        sample_titles = [\n",
    "            \"Machine Learning Research Paper\",\n",
    "            \"Deep Learning Applications\", \n",
    "            \"Natural Language Processing\",\n",
    "            \"Computer Vision Advances\",\n",
    "            \"Reinforcement Learning\",\n",
    "            \"Neural Networks Study\",\n",
    "            \"AI Ethics and Society\",\n",
    "            \"Quantum Computing Research\",\n",
    "            \"Data Mining Techniques\",\n",
    "            \"Robotics and Automation\"\n",
    "        ]\n",
    "        \n",
    "        # FIXED: Generate metadata for ALL vectors, not just first 5\n",
    "        for i in range(num_vectors):\n",
    "            title = sample_titles[i % len(sample_titles)]  # Cycle through titles\n",
    "            metadatas.append({\n",
    "                \"title\": f\"{title} #{i}\",\n",
    "                \"authors\": [f\"Author_{i}\", f\"Researcher_{i % 5}\"],\n",
    "                \"year\": 2020 + (i % 5),\n",
    "                \"abstract\": f\"This is a test abstract for {title} - document {i}\",\n",
    "                \"doc_id\": f\"doc_{i}\",\n",
    "                \"is_public\": i % 2 == 0  # Alternate public/private\n",
    "            })\n",
    "        \n",
    "        print(f\"  âœ… Generated {len(vectors)} embeddings, {len(ids)} IDs, {len(metadatas)} metadata entries\")\n",
    "        return vectors, ids, metadatas\n",
    "\n",
    "    # Generate larger batch with FIXED function\n",
    "    large_vectors, large_ids, large_metadatas = generate_large_sample_embeddings(\n",
    "        num_vectors=20, \n",
    "        dimension=384\n",
    "    )\n",
    "    \n",
    "    print(f\"â±ï¸  Testing with {len(large_vectors)} vectors...\")\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    # Test upsert performance\n",
    "    start_time = time.time()\n",
    "    results = await vector_db.upsert_embeddings(\n",
    "        vectors=large_vectors,\n",
    "        ids=[f\"perf_test_{id}\" for id in large_ids],\n",
    "        metadatas=large_metadatas,\n",
    "        namespace=\"performance_test\"\n",
    "    )\n",
    "    upsert_time = time.time() - start_time\n",
    "    \n",
    "    successes = len([r for r in results if r[\"status\"] == \"success\"])\n",
    "    print(f\"  ðŸ“ˆ Upsert Performance: {successes} docs in {upsert_time:.2f}s \"\n",
    "          f\"({successes/upsert_time:.1f} docs/sec)\")\n",
    "    \n",
    "    # Test search performance\n",
    "    start_time = time.time()\n",
    "    search_results = await vector_db.search(\n",
    "        query_embedding=large_vectors[0],\n",
    "        top_k=10,\n",
    "        namespace=\"performance_test\"\n",
    "    )\n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"  ðŸ“ˆ Search Performance: {len(search_results)} results in {search_time:.4f}s\")\n",
    "    \n",
    "    # Verify search results\n",
    "    if search_results:\n",
    "        print(f\"  ðŸ” Best match: {search_results[0]['id']} (distance: {search_results[0]['distance']:.4f})\")\n",
    "    \n",
    "    # Clean up performance test data\n",
    "    delete_results = await vector_db.delete([f\"perf_test_{id}\" for id in large_ids])\n",
    "    delete_successes = len([r for r in delete_results if r[\"status\"] == \"success\"])\n",
    "    print(f\"  ðŸ§¹ Cleaned up {delete_successes} performance test documents\")\n",
    "\n",
    "# Run test\n",
    "await test_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a1be6-530a-49b6-b5f2-08d6752b976d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test 7: Edge Cases Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b689aa-a2e8-42c2-9461-c642e2b7e3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.services.vector_db.local_vector_db:Upserted batch of 2 vectors to Firestore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Test 7: Testing Edge Cases...\n",
      "\n",
      "ðŸ” Test 7.1: Empty inputs\n",
      "  âœ… Empty upsert handled: []\n",
      "\n",
      "ðŸ” Test 7.2: Similar vectors search\n",
      "  Similar vectors distance: 0.018226\n",
      "  âœ… Similar vectors test completed\n",
      "\n",
      "ðŸ” Test 7.3: Non-existent namespace\n",
      "  Search in non-existent namespace returned: 0 results\n",
      "  âœ… Non-existent namespace handled correctly\n"
     ]
    }
   ],
   "source": [
    "# Test 7: Edge Cases Test\n",
    "async def test_edge_cases():\n",
    "    print(f\"\\nðŸ§ª Test 7: Testing Edge Cases...\")\n",
    "    \n",
    "    # Test 7.1: Empty inputs\n",
    "    print(f\"\\nðŸ” Test 7.1: Empty inputs\")\n",
    "    try:\n",
    "        results = await vector_db.upsert_embeddings([], [], [])\n",
    "        print(f\"  âœ… Empty upsert handled: {results}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Empty upsert failed: {e}\")\n",
    "    \n",
    "    # Test 7.2: Very similar vectors\n",
    "    print(f\"\\nðŸ” Test 7.2: Similar vectors search\")\n",
    "    try:\n",
    "        # Create two very similar vectors\n",
    "        base_vector = np.random.randn(384).astype(np.float32)\n",
    "        base_vector = base_vector / np.linalg.norm(base_vector)\n",
    "        \n",
    "        similar_vector = base_vector + 0.01 * np.random.randn(384)\n",
    "        similar_vector = similar_vector / np.linalg.norm(similar_vector)\n",
    "        \n",
    "        # Store them\n",
    "        await vector_db.upsert_embeddings(\n",
    "            vectors=[base_vector.tolist(), similar_vector.tolist()],\n",
    "            ids=[\"similar_1\", \"similar_2\"],\n",
    "            metadatas=[{\"test\": \"similar_1\"}, {\"test\": \"similar_2\"}],\n",
    "            namespace=\"similarity_test\"\n",
    "        )\n",
    "        \n",
    "        # Search and check distance\n",
    "        results = await vector_db.search(\n",
    "            query_embedding=base_vector.tolist(),\n",
    "            top_k=2,\n",
    "            namespace=\"similarity_test\"\n",
    "        )\n",
    "        \n",
    "        print(f\"  Similar vectors distance: {results[1]['distance']:.6f}\")\n",
    "        print(f\"  âœ… Similar vectors test completed\")\n",
    "        \n",
    "        # Clean up\n",
    "        await vector_db.delete([\"similar_1\", \"similar_2\"])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Similar vectors test failed: {e}\")\n",
    "    \n",
    "    # Test 7.3: Non-existent namespace search\n",
    "    print(f\"\\nðŸ” Test 7.3: Non-existent namespace\")\n",
    "    try:\n",
    "        results = await vector_db.search(\n",
    "            query_embedding=vectors[0],\n",
    "            top_k=5,\n",
    "            namespace=\"non_existent_namespace_12345\"\n",
    "        )\n",
    "        print(f\"  Search in non-existent namespace returned: {len(results)} results\")\n",
    "        print(f\"  âœ… Non-existent namespace handled correctly\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Non-existent namespace search failed: {e}\")\n",
    "\n",
    "# Run test\n",
    "await test_edge_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c0870d-3f94-4f27-8dfe-fb20b2c458b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Final Summary and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b369263-6039-4d63-950f-b30e171f207e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ðŸ“Š FINAL TEST SUMMARY\n",
      "==================================================\n",
      "Final collection stats: {'vectors_count': 13, 'namespaces': ['test_namespace', 'user_123', 'public'], 'shards_count': 1, 'collection_name': 'vectors'}\n",
      "\n",
      "ðŸ“‚ Documents by namespace:\n",
      "  user_123: 3 documents\n",
      "  public: 5 documents\n",
      "  test_namespace: 5 documents\n",
      "  performance_test: 0 documents\n",
      "  similarity_test: 0 documents\n",
      "\n",
      "ðŸŽ¯ Test Suite Completed!\n",
      "âœ… Firestore Local Vector DB is working correctly\n",
      "ðŸ’¡ Use VECTOR_DB_TYPE=local in your environment to enable this service\n"
     ]
    }
   ],
   "source": [
    "# Final Summary and Cleanup\n",
    "async def final_summary():\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"ðŸ“Š FINAL TEST SUMMARY\")\n",
    "    print(f\"=\"*50)\n",
    "    \n",
    "    # Get final stats\n",
    "    stats = await vector_db.get_index_stats()\n",
    "    print(f\"Final collection stats: {stats}\")\n",
    "    \n",
    "    # Count documents by namespace\n",
    "    print(f\"\\nðŸ“‚ Documents by namespace:\")\n",
    "    namespaces = [\"user_123\", \"public\", \"test_namespace\", \"performance_test\", \"similarity_test\"]\n",
    "    \n",
    "    for namespace in namespaces:\n",
    "        try:\n",
    "            results = await vector_db.search(\n",
    "                query_embedding=vectors[0],\n",
    "                top_k=100,  # Large number to count all\n",
    "                namespace=namespace\n",
    "            )\n",
    "            print(f\"  {namespace}: {len(results)} documents\")\n",
    "        except:\n",
    "            print(f\"  {namespace}: 0 documents (or error)\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Test Suite Completed!\")\n",
    "    print(f\"âœ… Firestore Local Vector DB is working correctly\")\n",
    "    print(f\"ðŸ’¡ Use VECTOR_DB_TYPE=local in your environment to enable this service\")\n",
    "\n",
    "# Run final summary\n",
    "await final_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5734e7e-499c-453b-b4e2-0966f713e4da",
   "metadata": {},
   "source": [
    "# Quick health check function for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89b0ea80-b7ec-4631-8905-af0b7f56ee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¥ Running Quick Health Check...\n",
      "ðŸŸ¢ Vector DB Healthy - Total vectors: 13\n"
     ]
    }
   ],
   "source": [
    "# Quick health check function for future use\n",
    "async def health_check():\n",
    "    \"\"\"Quick health check for the vector DB\"\"\"\n",
    "    try:\n",
    "        stats = await vector_db.get_index_stats()\n",
    "        print(f\"ðŸŸ¢ Vector DB Healthy - Total vectors: {stats.get('vectors_count', 0)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ”´ Vector DB Unhealthy: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run quick health check\n",
    "print(f\"\\nðŸ¥ Running Quick Health Check...\")\n",
    "is_healthy = await health_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ed411-9319-4578-b5ed-dfc1205a2441",
   "metadata": {},
   "source": [
    "# Miscs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d4238283-9da7-4f10-90e8-7db123e6d038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectors_count': 18,\n",
       " 'namespaces': ['public', 'test_namespace', 'user_123', 'user007'],\n",
       " 'shards_count': 1,\n",
       " 'collection_name': 'vectors'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await vector_db.get_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5974440-8dcc-415f-9f3e-7881c0b596cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method upsert_embeddings in module src.services.vector_db.local_vector_db:\n",
      "\n",
      "async upsert_embeddings(vectors: List[List[float]], ids: List[str], metadatas: List[Dict[str, Any]], namespace: Optional[str] = None) method of src.services.vector_db.local_vector_db.LocalVectorDBService instance\n",
      "    Upsert embeddings into Firestore with vector support.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(vector_db.upsert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "649102ff-13e9-40c0-b437-c9ddd6a7a558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.services.vector_db.local_vector_db:Upserted batch of 1 vectors to Firestore\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'status': 'success', 'id': 'abc5'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await vector_db.upsert_embeddings(vectors=[[.35]*384,], \n",
    "                                  ids=['abc5',], \n",
    "                                  metadatas=[{'a': 2, 'b': 3}], \n",
    "                                  namespace='user007')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e527c3c-e9e9-4cf7-9b8d-cd90435408a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectors_count': 21,\n",
       " 'namespaces': ['test_namespace',\n",
       "  'user009',\n",
       "  'user2',\n",
       "  'user310',\n",
       "  'user007',\n",
       "  'user_123',\n",
       "  'public'],\n",
       " 'shards_count': 1,\n",
       " 'collection_name': 'vectors'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await vector_db.get_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5c8a01c-9353-417e-bcda-1c3d5a0902f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method search in module src.services.vector_db.local_vector_db:\n",
      "\n",
      "async search(query_embedding: List[float], top_k: int, namespace: Optional[str] = None, filter: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]] method of src.services.vector_db.local_vector_db.LocalVectorDBService instance\n",
      "    Search for similar vectors using cosine similarity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(vector_db.search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "781dae79-67a9-4e57-87d3-c867bd5bff16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'abc5',\n",
       "  'distance': np.float64(1.1102230246251565e-16),\n",
       "  'metadata': {'b': 3, 'a': 2}},\n",
       " {'id': 'abc1',\n",
       "  'distance': np.float64(2.220446049250313e-16),\n",
       "  'metadata': {'b': 3, 'a': 2}}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await vector_db.search(query_embedding=[0.35]*384,\n",
    "                       top_k=2,\n",
    "                       namespace=\"user007\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbe3a260-c79d-49d1-8723-4e0027de307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/google/cloud/firestore_v1/base_collection.py:304: UserWarning: Detected filter using positional arguments. Prefer using the 'filter' keyword argument instead.\n",
      "  return query.where(field_path, op_string, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'user310_b7911978-2c06-4061-8dbf-5050f46f19d3',\n",
       "  'distance': np.float64(0.9873289903297738),\n",
       "  'metadata': {'publication_date': None,\n",
       "   'user_id': 'user310',\n",
       "   'authors': [],\n",
       "   'doc_id': 'b7911978-2c06-4061-8dbf-5050f46f19d3',\n",
       "   'namespace': 'user310',\n",
       "   'text_preview': 'Â©          Nature Publishing Group\\n1953\\nNo. 4356\\nApril 25, 1953\\nNATURE\\n737\\nThis\\nfigure\\nis\\npurely\\ndiagrammatic. The two\\nribbons symbolize the\\ntwo\\nphosphate-sugar\\nchains, and the hori-\\nzontal rods the p...',\n",
       "   'filename': 'WatsonCrick1953.pdf',\n",
       "   'journal': None,\n",
       "   'is_public': False,\n",
       "   'title': 'WatsonCrick1953.pdf'}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await vector_db.search(query_embedding=[1]*384,\n",
    "                       top_k=10,\n",
    "                       namespace=\"user310\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3148770e-12cf-4e0a-87b7-9e98cb2543f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector =  [-0.08533287048339844, 0.06320766359567642, -0.05387697368860245, -0.012143664062023163, -0.039499204605817795, 0.007550196722149849, -0.010784433223307133, 0.02410038374364376, -0.012486048974096775, -0.0017627258785068989, 0.02419915236532688, 0.05066535621881485, -0.07333450019359589, 0.004249769728630781, -0.08437206596136093, 0.06910083442926407, -0.09553465247154236, 0.03943271562457085, 0.019373342394828796, -0.06292670965194702, -0.04554183781147003, 0.01868239976465702, 0.07621124386787415, -0.011143232695758343, -0.012767351232469082, 0.07841664552688599, -0.002308505354449153, 0.010973022319376469, 0.03595571219921112, -0.053781650960445404, 0.07792655378580093, -0.013682946562767029, 0.020831771194934845, -0.011518816463649273, -0.016729161143302917, 0.018863700330257416, 0.05099675804376602, 0.03931378200650215, 0.011224928312003613, -0.02155255153775215, 0.0655590072274208, 0.006225470453500748, -0.026553748175501823, 0.13485614955425262, -0.04091698303818703, 0.06857798993587494, 0.05803070217370987, 0.048606015741825104, -0.03198649361729622, 0.02669346332550049, -0.007402851711958647, 0.03202458843588829, -0.01701812632381916, -0.025494588539004326, -0.004538432694971561, 0.0992225930094719, 0.0031316494569182396, -0.11517127603292465, -0.0016264505684375763, 0.022243130952119827, 0.08529284596443176, -0.05047579109668732, 4.5627442887052894e-05, 0.0009597937460057437, 0.11981269717216492, -0.005669879261404276, 0.07470890879631042, -0.03762474283576012, -0.016144007444381714, -0.06479991227388382, 0.017802894115447998, -0.017281800508499146, 0.03861672058701515, 0.048282917588949203, 0.008790770545601845, 0.007283375132828951, -0.03435134142637253, -0.055734820663928986, -0.019888821989297867, 0.1076444610953331, -0.058844320476055145, -0.07172531634569168, 0.006923135835677385, 0.023207608610391617, -0.011990099214017391, -0.03280875086784363, 0.06460632383823395, 0.03647578880190849, -0.036100614815950394, 0.0814611166715622, -0.09594447165727615, -0.026434509083628654, 0.069469153881073, -0.05066205933690071, -0.09883996099233627, 0.04510064795613289, 0.026256700977683067, -0.002860547974705696, 0.08153462409973145, 0.011127176694571972, -0.011633064597845078, -0.04997675493359566, -0.0752483382821083, -0.016100700944662094, -0.039464615285396576, -0.0204386655241251, -0.018704883754253387, -0.051259901374578476, 0.04636237397789955, -0.00139285356272012, -0.09742899984121323, 0.03802228718996048, -0.08427175879478455, 0.01753644086420536, -0.054727889597415924, -0.07330755889415741, 0.05590727925300598, -0.0023529776372015476, 0.024532394483685493, 0.010527241043746471, 0.02014165371656418, -0.01898735947906971, 0.029375987127423286, 0.003994782455265522, 0.01221164409071207, -0.04970862343907356, -0.024886833503842354, -9.963653217410886e-33, -0.023432744666934013, -0.023082146421074867, 0.023603731766343117, 0.01257326640188694, -0.013141063041985035, 0.05215912684798241, -0.01931684836745262, 0.011101225391030312, -0.14605362713336945, 0.02777140773832798, -0.023429110646247864, -0.061470430344343185, 0.07261207699775696, 0.026576748117804527, -0.027827071025967598, 0.07294709980487823, -0.09049038589000702, -0.0012167638633400202, -0.008118044584989548, -0.0159293320029974, -0.03101527877151966, 0.029244573786854744, -0.0053628915920853615, 0.008256728760898113, 0.020235523581504822, -0.0028019710443913937, -0.04873496666550636, -0.006920344196259975, 0.12933507561683655, -0.03802759200334549, -0.006026070099323988, -0.030194710940122604, 0.03016921691596508, 0.04274723678827286, 0.08155557513237, 0.06508582085371017, 0.04461285099387169, -0.03456072509288788, 0.049432288855314255, 0.10238329321146011, -0.048643313348293304, -0.05536014214158058, 0.029778340831398964, -0.07861531525850296, 0.04019642248749733, -0.007291090674698353, 0.007094314321875572, -0.12434857338666916, -0.1599123477935791, 0.004601133055984974, -0.020431403070688248, -0.06117594242095947, 0.007727866526693106, 0.0012544011697173119, -0.030100857838988304, 0.0111935343593359, -0.03409412503242493, 0.019648917019367218, -0.06251687556505203, 0.040291015058755875, -0.016211966052651405, 0.046666208654642105, -0.03312103450298309, 0.002359357662498951, 0.08046545088291168, -0.06217731162905693, 0.011035485193133354, -0.011882679536938667, 0.1113336831331253, 0.002472342923283577, 0.08270048350095749, -0.05266692489385605, -0.0043308185413479805, 0.012113873846828938, 0.016892649233341217, 0.07485593110322952, -0.08653387427330017, -0.020224757492542267, -0.09040670096874237, 0.06816992908716202, -0.05454012006521225, -0.025298919528722763, 0.011182673275470734, -0.06019110232591629, -0.02348862588405609, 0.04027552157640457, -0.08663056790828705, -0.03798661008477211, 0.027609484270215034, -0.028922822326421738, 0.03741922974586487, -0.07406778633594513, -0.007277278695255518, -0.14549526572227478, 0.04574810713529587, 4.241780915833825e-33, 0.05708735063672066, -0.08079569041728973, 0.01966448500752449, 0.06122260168194771, 0.0007716532563790679, -0.0999399721622467, 0.05183149874210358, 0.11116880923509598, 0.001987385330721736, 0.013450060971081257, 0.043279845267534256, -0.056606799364089966, 0.01727987453341484, -0.020304877310991287, 0.013308452442288399, 0.01634853519499302, 0.0019935264717787504, 0.03884073346853256, 0.04412056878209114, 0.045426711440086365, -0.019499365240335464, 0.0788140818476677, -0.031042061746120453, 0.030786506831645966, 0.012223545461893082, -0.037807147949934006, -0.0457841195166111, 0.013871788047254086, 0.07482399046421051, -0.03833424672484398, -0.1233457699418068, 0.010708640329539776, 0.0807511955499649, 0.00046469864901155233, 0.06227744743227959, 0.03855273500084877, 0.07165703922510147, 0.057791732251644135, 0.030867379158735275, -0.031994692981243134, -0.0881940945982933, 0.10427526384592056, -0.07915260642766953, 0.009461699053645134, -0.007622865028679371, 0.04222763702273369, -0.015836700797080994, 0.09821775555610657, -0.025047294795513153, 5.660894385073334e-05, -0.009490152820944786, 0.01862039417028427, 0.009072774089872837, -0.07719580829143524, 0.01952219009399414, -0.034877851605415344, -0.004846116062253714, -0.03641827777028084, 0.045342739671468735, 0.11328764259815216, 0.07033498585224152, -0.03148656338453293, -0.021632522344589233, 0.005436321720480919, -0.018396146595478058, 0.055580999702215195, -0.03274228051304817, 0.02729525975883007, -0.01347374077886343, -0.027900414541363716, 0.03442836180329323, 0.009451204910874367, 0.034716345369815826, 0.03854938969016075, 0.016596874222159386, -0.04870692640542984, -0.07304654270410538, -0.008290898986160755, 0.019057398661971092, -0.00421536760404706, 0.013417547568678856, -0.08433642983436584, -0.020298711955547333, 0.02607601508498192, 0.11783704161643982, -0.02295668236911297, 0.021393686532974243, 0.04902345687150955, -0.05231544002890587, -0.055870190262794495, -0.02093527652323246, 0.031365443021059036, -0.05577091872692108, 0.03280707821249962, -0.03693254292011261, -1.5461541380545896e-08, 0.08316486328840256, -0.0859232246875763, 0.0017912626499310136, -0.09699346125125885, 0.042070385068655014, 0.06975790858268738, 0.017771778628230095, 0.007324211299419403, 0.060239873826503754, -0.016933942213654518, 0.004137400537729263, 0.06167007237672806, -0.046822916716337204, 0.0353974811732769, -0.003064175834879279, 0.015715697780251503, -0.019847821444272995, -0.05099118873476982, 0.0046591078862547874, 0.0524381585419178, 0.01329086534678936, 0.041092369705438614, -0.15533185005187988, 0.04834933951497078, 0.013248312287032604, 0.05052652955055237, 0.06338553130626678, 0.02509012632071972, 0.015886686742305756, -0.038277339190244675, -0.013269362971186638, -0.051046278327703476, 0.021145107224583626, 0.047841303050518036, -0.05881962180137634, -0.04995081573724747, 0.0675315111875534, -0.0347600020468235, 0.008880374021828175, -0.014999696053564548, 0.037935771048069, 0.08151311427354813, -0.06835751980543137, -0.029214495792984962, -0.012053891085088253, -0.024773186072707176, 0.009407216683030128, -0.00875867996364832, -0.0579652301967144, -0.04436656832695007, -0.00439862534403801, -0.051215723156929016, -0.0263687577098608, -0.05069563910365105, -0.02624211646616459, -0.02586251311004162, 0.010995126329362392, 0.01454547792673111, -0.08349516242742538, -0.02024334855377674, 0.04096848890185356, 0.04112539067864418, 0.13260547816753387, -0.08521678298711777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8fc801d-e4a2-45e6-912d-2df124a12b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/google/cloud/firestore_v1/base_collection.py:304: UserWarning: Detected filter using positional arguments. Prefer using the 'filter' keyword argument instead.\n",
      "  return query.where(field_path, op_string, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'user101_9689da65-8b5d-43fb-b405-61ef1def3baa',\n",
       "  'distance': np.float64(0.696872871315227),\n",
       "  'metadata': {'journal': None,\n",
       "   'user_id': 'user101',\n",
       "   'doc_id': '9689da65-8b5d-43fb-b405-61ef1def3baa',\n",
       "   'is_public': False,\n",
       "   'authors': [],\n",
       "   'title': 'WatsonCrick1953.pdf',\n",
       "   'namespace': 'user101',\n",
       "   'filename': 'WatsonCrick1953.pdf',\n",
       "   'publication_date': None,\n",
       "   'text_preview': 'Â©          Nature Publishing Group\\n1953\\nNo. 4356\\nApril 25, 1953\\nNATURE\\n737\\nThis\\nfigure\\nis\\npurely\\ndiagrammatic. The two\\nribbons symbolize the\\ntwo\\nphosphate-sugar\\nchains, and the hori-\\nzontal rods the p...'}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await vector_db.search(query_embedding=query_vector,\n",
    "                       top_k=10,\n",
    "                       namespace=\"user101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca34d792-5864-4c8c-b4a7-b9a7114f5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await vector_db.search(query_embedding=query_vector, \n",
    "                       top_k=10,\n",
    "                       namespace=\"user310\", \n",
    "                       filter={\"metadata.is_public\": [True,\n",
    "                                  False]})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7722760-938c-41de-8d11-fdf078185286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'user310_b7911978-2c06-4061-8dbf-5050f46f19d3',\n",
       "  'distance': np.float64(0.696872871315227),\n",
       "  'metadata': {'journal': None,\n",
       "   'user_id': 'user310',\n",
       "   'authors': [],\n",
       "   'is_public': False,\n",
       "   'doc_id': 'b7911978-2c06-4061-8dbf-5050f46f19d3',\n",
       "   'title': 'WatsonCrick1953.pdf',\n",
       "   'namespace': 'user310',\n",
       "   'filename': 'WatsonCrick1953.pdf',\n",
       "   'publication_date': None,\n",
       "   'text_preview': 'Â©          Nature Publishing Group\\n1953\\nNo. 4356\\nApril 25, 1953\\nNATURE\\n737\\nThis\\nfigure\\nis\\npurely\\ndiagrammatic. The two\\nribbons symbolize the\\ntwo\\nphosphate-sugar\\nchains, and the hori-\\nzontal rods the p...'}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbb2da86-27b6-4c0e-8590-408e1cf7e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    async def _build_context(relevant_papers: List[Dict[str, Any]],\n",
    "                             query_text: str) -> str:\n",
    "        \"\"\"Build context from relevant papers for the LLM\"\"\"\n",
    "        context_parts = []\n",
    "\n",
    "        for i, paper in enumerate(\n",
    "                relevant_papers[:5]):  # Limit to top 5 papers for context\n",
    "            metadata = paper.get('metadata', {})\n",
    "            doc_id = metadata.get('doc_id')\n",
    "\n",
    "            if not doc_id:\n",
    "                continue\n",
    "\n",
    "            # In a real implementation, you would retrieve the full text from storage\n",
    "            # For now, we'll use the metadata and a placeholder for text\n",
    "            context_parts.append(\n",
    "                f\"Paper {i+1}: {metadata.get('title', 'Unknown title')}\\n\"\n",
    "                f\"Authors: {', '.join(metadata.get('authors', []))}\\n\"\n",
    "                f\"Abstract: {metadata.get('abstract', 'No abstract available')}\\n\"\n",
    "                f\"Relevance score: {paper.get('score', 0):.3f}\\n\")\n",
    "\n",
    "        if not context_parts:\n",
    "            return \"No relevant research papers found for this query.\"\n",
    "\n",
    "        return \"\\n\".join(context_parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36631498-21c9-416c-b8e0-73b964e121aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "async def _build_context(relevant_papers: List[Dict[str, Any]],\n",
    "                         query_text: str) -> str:\n",
    "    \"\"\"Build context from relevant papers for the LLM by retrieving full text\"\"\"\n",
    "    context_parts = []\n",
    "    \n",
    "    # Get storage service (add this to your __init__ or get it when needed)\n",
    "    from src.services.storage import get_storage_service\n",
    "    storage_service = get_storage_service()\n",
    "\n",
    "    for i, paper in enumerate(relevant_papers[:5]):  # Limit to top 5 papers\n",
    "        metadata = paper.get('metadata', {})\n",
    "        doc_id = metadata.get('doc_id')\n",
    "\n",
    "        if not doc_id:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Try to get the full text from storage\n",
    "            \n",
    "            full_text = await _get_paper_full_text(metadata, storage_service)\n",
    "            print(\"*=\"*30)\n",
    "            print(\"*=\"*30)\n",
    "            print(f\"full text length {len(full_text)}\")\n",
    "            print(\"*=\"*30)\n",
    "            print(\"*=\"*30)\n",
    "            \n",
    "            # Use full text if available, otherwise fall back to abstract/preview\n",
    "            text_content = full_text if full_text else metadata.get('abstract', metadata.get('text_preview', 'No content available'))\n",
    "            \n",
    "            # Truncate text to reasonable length for LLM context\n",
    "            if len(text_content) > 2000:\n",
    "                text_content = text_content[:2000] + \"... [truncated]\"\n",
    "            \n",
    "            context_parts.append(\n",
    "                f\"Paper {i+1}: {metadata.get('title', 'Unknown title')}\\n\"\n",
    "                f\"Authors: {', '.join(metadata.get('authors', []))}\\n\"\n",
    "                f\"Content: {text_content}\\n\"\n",
    "                f\"Relevance score: {1 - paper.get('distance', 1):.3f}\\n\"  # Convert distance to similarity\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to retrieve full text for paper {doc_id}: {e}\")\n",
    "            # Fallback to metadata-only approach\n",
    "            context_parts.append(\n",
    "                f\"Paper {i+1}: {metadata.get('title', 'Unknown title')}\\n\"\n",
    "                f\"Authors: {', '.join(metadata.get('authors', []))}\\n\"\n",
    "                f\"Abstract: {metadata.get('abstract', 'No abstract available')}\\n\"\n",
    "                f\"Preview: {metadata.get('text_preview', 'No preview available')}\\n\"\n",
    "                f\"Relevance score: {1 - paper.get('distance', 1):.3f}\\n\"\n",
    "            )\n",
    "\n",
    "    if not context_parts:\n",
    "        return \"No relevant research papers found for this query.\"\n",
    "\n",
    "    return \"\\n\".join(context_parts)\n",
    "\n",
    "async def _get_paper_full_text(metadata: Dict[str, Any], storage_service) -> Optional[str]:\n",
    "    \"\"\"Retrieve the full text of a paper from storage\"\"\"\n",
    "    try:\n",
    "        # Method 1: Check if we have raw_text_path in metadata (from vector DB)\n",
    "        raw_text_path = metadata.get('raw_text_path')\n",
    "        if raw_text_path:\n",
    "            text_content = await storage_service.download_file(raw_text_path)\n",
    "            return text_content.decode('utf-8') if isinstance(text_content, bytes) else text_content\n",
    "\n",
    "        print(\"*=\"*30)\n",
    "        print(f\"txt content: {len(text_content)}\")\n",
    "        print(f\"{metadata}\")\n",
    "        print(\"*=\"*30)\n",
    "        \n",
    "        # Method 2: Try to reconstruct the path from doc_id and user_id\n",
    "        doc_id = metadata.get('doc_id')\n",
    "        user_id = metadata.get('user_id')\n",
    "        if doc_id and user_id:\n",
    "            # Reconstruct the path pattern used in file_processing.py\n",
    "            possible_paths = [\n",
    "                f\"users/{user_id}/text/{doc_id}.txt\",\n",
    "                f\"users/{user_id}/text/{doc_id}\",\n",
    "                f\"text/{doc_id}.txt\"\n",
    "            ]\n",
    "            \n",
    "            for path in possible_paths:\n",
    "                try:\n",
    "                    if await storage_service.file_exists(path):\n",
    "                        text_content = await storage_service.download_file(path)\n",
    "                        return text_content.decode('utf-8') if isinstance(text_content, bytes) else text_content\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # Method 3: For production Vertex AI, we might need to query the paper database\n",
    "        # This would require additional paper DB service integration\n",
    "        logger.debug(f\"Could not find full text for paper {metadata.get('doc_id')}\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error retrieving full text for paper: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e731e32-bb32-4958-a3cf-076c14052343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.services.storage:Using Mock Storage Service (development mode)\n",
      "INFO:src.services.storage.mock_storage:Initializing Mock Storage Service for development\n",
      "WARNING:__main__:Error retrieving full text for paper: cannot access local variable 'text_content' where it is not associated with a value\n",
      "WARNING:__main__:Failed to retrieve full text for paper b7911978-2c06-4061-8dbf-5050f46f19d3: object of type 'NoneType' has no len()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=\n",
      "*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=\n",
      "*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=\n"
     ]
    }
   ],
   "source": [
    "cnxt = await _build_context(results, 'dna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18b6c24d-b08f-42c1-af34-07f75e1cd225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28880c8b-89e7-410c-8a7d-ca81db4e03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f34e065-23e4-4799-89b5-16dd1f570697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journal': None,\n",
       " 'user_id': 'user310',\n",
       " 'authors': [],\n",
       " 'is_public': False,\n",
       " 'doc_id': 'b7911978-2c06-4061-8dbf-5050f46f19d3',\n",
       " 'title': 'WatsonCrick1953.pdf',\n",
       " 'namespace': 'user310',\n",
       " 'filename': 'WatsonCrick1953.pdf',\n",
       " 'publication_date': None,\n",
       " 'text_preview': 'Â©          Nature Publishing Group\\n1953\\nNo. 4356\\nApril 25, 1953\\nNATURE\\n737\\nThis\\nfigure\\nis\\npurely\\ndiagrammatic. The two\\nribbons symbolize the\\ntwo\\nphosphate-sugar\\nchains, and the hori-\\nzontal rods the p...'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82086fe2-d421-40dc-b042-c62c9347a81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
